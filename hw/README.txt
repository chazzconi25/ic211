Title: Artificial Intelligence: Can We Trust Machines to Make Fair Decisions?
Source: https://www.ucdavis.edu/curiosity/news/ais-race-and-gender-problem

The article, Artificial Intelligence: Can We Trust Machines to Make Fair 
Decisions?, highlights prominent issues with bias that can be implemented into 
Artificial Intelligence information systems. The article highlights a few 
examples of where AI bias can impact real world consequences. In policing AI 
is used in facial recognition to find suspects from body camera photos. While 
this technology is very beneficial to police officers, researchers found that 
the AI was more likely to suspect persons of color. The article goes on to 
describe how this can be taken a step further when AI is used to predict risk 
assessments or “anomaly detection”. Unfortunately AI bias can have even more 
serious consequences when this surveillance technology predicts who is acting 
suspiciously.

The article goes on to highlight that the bias in AI is primarily a result of 
a biased world. In research darker skin tones are not tested and leads to 
decreased AI effectiveness in both medical and automated transportation 
systems. The article concludes that a combination of greater awareness of AI 
bias and more diversity in research teams could ameliorate biases in AI. 

The article makes a compelling argument for AI and how we should approach 
research within the field, especially as it becomes more prevalent in 
policing. While I was reading, two principles of the ACM’s Code of Ethics 
seemed most important. First, principle 1.1, Contribute to society and to 
human well-being, acknowledging that all people are stakeholders in computing. 
Second, principle 3.7, Recognize and take special care of systems that become 
integrated into the infrastructure of society.

In principle 1.1 it is critical that researchers take the time to understand 
and develop their systems with all people as stakeholders in mind. In the 
examples described in the article the researchers highlight that this was not 
done originally with AI and bias developed as a result. Future research into 
AI needs to appreciate the need for diversity of people developing it as well 
as diverse data training sources.

In principle 3.7 there is a direct connection to the article. The article 
highlights specifically the impact of AI in its application to society. Whether
it's policing, medicine, or automated cars, AI and the way it is researched 
and developed can have serious implications in its practical application. 
Researchers in AI need to take special care to recognize that “[system
creators’] stewardship requires establishing policies for fair system access, 
including for those who may have been excluded”. In the case of AI this means 
making sure diverse research teams can access this new frontier of research and 
all members of society can contribute to the data required for AI.
